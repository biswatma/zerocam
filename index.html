<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Camera Interaction App</title>
  <style>
    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background-color: #f9f9f9;
      color: #333;
    }

    h1 {
      text-align: center;
      padding: 20px 0;
      font-size: 2rem;
    }

    .container {
      display: flex;
      flex-direction: column;
      gap: 20px;
      padding: 20px;
    }

    @media (min-width: 900px) {
      .container {
        flex-direction: row;
        justify-content: center;
        align-items: flex-start;
        gap: 40px;
      }
    }

    #videoContainer {
      position: relative;
      width: 100%;
      max-width: 640px;
      aspect-ratio: 4 / 3;
      background-color: #000;
      border-radius: 12px;
      overflow: hidden;
      border: 3px solid #333;
      box-shadow: 0 4px 20px rgba(0,0,0,0.1);
    }

    #videoFeed {
      width: 100%;
      height: 100%;
      object-fit: cover;
    }

    #loadingOverlay {
      position: absolute;
      inset: 0;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      background-color: rgba(0, 0, 0, 0.75);
      z-index: 10;
      color: white;
      font-size: 1.2rem;
      font-weight: bold;
    }

    .loader {
      border: 4px solid #f3f3f3;
      border-top: 4px solid #3498db;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      animation: spin 1s linear infinite;
      margin-bottom: 10px;
    }

    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }

    .right-panel {
      flex: 1;
      display: flex;
      flex-direction: column;
      gap: 20px;
      max-width: 600px;
    }

    .io-areas, .controls {
      background-color: white;
      border-radius: 12px;
      padding: 20px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.08);
      display: flex;
      flex-direction: column;
      gap: 16px;
    }

    textarea {
      width: 100%;
      padding: 10px;
      font-size: 1rem;
      border-radius: 8px;
      border: 1px solid #ccc;
      resize: vertical;
      min-height: 60px;
    }

    label {
      font-weight: 600;
    }

    select, button {
      padding: 10px;
      border-radius: 8px;
      font-size: 1rem;
      border: 1px solid #ccc;
      cursor: pointer;
    }

    #startButton.start {
      background-color: #28a745;
      color: white;
      border: none;
    }

    #startButton.stop {
      background-color: #dc3545;
      color: white;
      border: none;
    }

    canvas.hidden {
      display: none;
    }
  </style>
</head>
<body>
  <h1>Camera Interaction App</h1>
  <div class="container">
    <div id="videoContainer">
      <video id="videoFeed" autoplay playsinline></video>
      <div id="loadingOverlay">
        <div class="loader"></div>
        <div id="loadingText">Loading... 0%</div>
      </div>
    </div>

    <canvas id="canvas" class="hidden"></canvas>

    <div class="right-panel">
      <div class="io-areas">
        <div>
          <label for="instructionText">Instruction:</label>
          <textarea id="instructionText" name="Instruction"></textarea>
        </div>
        <div>
          <label for="responseText">Response:</label>
          <textarea id="responseText" name="Response" readonly placeholder="Server response will appear here..."></textarea>
        </div>
      </div>

      <div class="controls">
        <label for="intervalSelect">Interval between 2 requests:</label>
        <select id="intervalSelect">
          <option value="0">0ms</option>
          <option value="100">100ms</option>
          <option value="250">250ms</option>
          <option value="500">500ms</option>
          <option value="1000">1s</option>
          <option value="2000">2s</option>
        </select>
        <button id="startButton" class="start">Start</button>
      </div>
    </div>
  </div>

  <script type="module">
    import {
      AutoProcessor,
      AutoModelForVision2Seq,
      RawImage,
    } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers/dist/transformers.min.js";

    const video = document.getElementById("videoFeed");
    const canvas = document.getElementById("canvas");
    const instructionText = document.getElementById("instructionText");
    const responseText = document.getElementById("responseText");
    const intervalSelect = document.getElementById("intervalSelect");
    const startButton = document.getElementById("startButton");
    const loadingOverlay = document.getElementById("loadingOverlay");
    const loadingText = document.getElementById("loadingText");

    instructionText.value = "What do you see?";

    let stream, processor, model;
    let isProcessing = false;

    async function updateProgress(message, percent) {
      loadingText.textContent = `${message} ${percent}%`;
    }

    async function initModel() {
      try {
        const modelId = "HuggingFaceTB/SmolVLM-500M-Instruct";
        await updateProgress("Loading processor...", 10);
        processor = await AutoProcessor.from_pretrained(modelId);
        await updateProgress("Processor loaded. Loading model...", 40);
        model = await AutoModelForVision2Seq.from_pretrained(modelId, {
          dtype: {
            embed_tokens: "fp16",
            vision_encoder: "q4",
            decoder_model_merged: "q4",
          },
          device: "webgpu",
        });
        await updateProgress("Model loaded. Starting camera...", 90);
        loadingOverlay.style.display = "none";
      } catch (err) {
        loadingText.textContent = "Error loading model!";
        console.error(err);
      }
    }

    async function initCamera() {
      try {
        stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        video.srcObject = stream;
        responseText.value = "Camera access granted. Ready to start.";
      } catch (err) {
        responseText.value = `Error accessing camera: ${err.name} - ${err.message}`;
        alert("Error accessing camera. Ensure permissions and HTTPS.");
      }
    }

    function captureImage() {
      if (!stream || !video.videoWidth) return null;
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext("2d", { willReadFrequently: true });
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      return new RawImage(frame.data, frame.width, frame.height, 4);
    }

    async function runLocalVisionInference(imgElement, instruction) {
      const messages = [
        { role: "user", content: [{ type: "image" }, { type: "text", text: instruction }] },
      ];
      const text = processor.apply_chat_template(messages, { add_generation_prompt: true });
      const inputs = await processor(text, [imgElement], { do_image_splitting: false });
      const generatedIds = await model.generate({ ...inputs, max_new_tokens: 100 });
      const output = processor.batch_decode(
        generatedIds.slice(null, [inputs.input_ids.dims.at(-1), null]),
        { skip_special_tokens: true }
      );
      return output[0].trim();
    }

    async function sendData() {
      if (!isProcessing) return;
      const instruction = instructionText.value;
      const rawImg = captureImage();
      if (!rawImg) {
        responseText.value = "Capture failed";
        return;
      }
      try {
        const reply = await runLocalVisionInference(rawImg, instruction);
        responseText.value = reply;
      } catch (e) {
        console.error(e);
        responseText.value = `Error: ${e.message}`;
      }
    }

    function sleep(ms) {
      return new Promise(res => setTimeout(res, ms));
    }

    async function processingLoop() {
      const interval = parseInt(intervalSelect.value, 10);
      while (isProcessing) {
        await sendData();
        await sleep(interval);
      }
    }

    function handleStart() {
      if (!stream) {
        responseText.value = "Camera not available.";
        alert("Camera not available.");
        return;
      }
      isProcessing = true;
      startButton.textContent = "Stop";
      startButton.classList.replace("start", "stop");
      instructionText.disabled = true;
      intervalSelect.disabled = true;
      responseText.value = "Processing started...";
      processingLoop();
    }

    function handleStop() {
      isProcessing = false;
      startButton.textContent = "Start";
      startButton.classList.replace("stop", "start");
      instructionText.disabled = false;
      intervalSelect.disabled = false;
      if (responseText.value.startsWith("Processing started...")) {
        responseText.value = "Processing stopped.";
      }
    }

    startButton.addEventListener("click", () => {
      isProcessing ? handleStop() : handleStart();
    });

    window.addEventListener("DOMContentLoaded", async () => {
      if (!navigator.gpu) {
        const msg = document.createElement("p");
        msg.textContent = "WebGPU not supported in this browser.";
        msg.style.color = "red";
        msg.style.textAlign = "center";
        document.body.insertBefore(msg, document.body.firstChild);
      }
      await initModel();
      await initCamera();
    });

    window.addEventListener("beforeunload", () => {
      if (stream) stream.getTracks().forEach(track => track.stop());
    });
  </script>
</body>
</html>
